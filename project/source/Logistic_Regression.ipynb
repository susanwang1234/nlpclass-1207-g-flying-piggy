{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import svm\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "#vec = CountVectorizer(max_features = 100)\n",
    "train_tokens = vec.fit_transform(train['comment_text'])\n",
    "test_tokens = vec.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "global_tokens = vstack([train_tokens, test_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, n_iter=10)\n",
    "svd.fit(global_tokens)\n",
    "global_svd = svd.transform(global_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(global_svd)\n",
    "global_scaled = scaler.transform(global_svd)\n",
    "train_scaled = global_scaled[:len(train)]\n",
    "test_scaled = global_scaled[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c493b65b064a8a983c279f8a40c7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training toxic\n",
      "Training severe_toxic\n",
      "Training obscene\n",
      "Training threat\n",
      "Training insult\n",
      "Training identity_hate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_on_test = np.zeros((len(test), len(labels)))\n",
    "predict_on_train = np.zeros((len(train), len(labels)))\n",
    "for idx, label in tqdm(enumerate(labels)):\n",
    "    print(\"Training %s\"%(label))\n",
    "    m = LogisticRegression().fit(train_scaled, train[label])\n",
    "    predict_on_test[:,idx] = m.predict_proba(test_scaled)[:,1]\n",
    "    predict_on_train[:,idx] = m.predict_proba(train_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "def crossValidation(clf, X, y, n=5):\n",
    "    cv = KFold(n_splits=n)\n",
    "    scores = []\n",
    "    i = 0\n",
    "    y_pred  = []\n",
    "    y_true = []\n",
    "    # split the training data to training and validation data\n",
    "    for train_index, valid_index in cv.split(X):\n",
    "        i += 1\n",
    "        X_tr, X_va, y_tr, y_va = X[train_index], X[valid_index], y.iloc[train_index], y.iloc[valid_index]\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pred_sub = clf.predict(X_va)\n",
    "        newScore = clf.score(X_va, y_va)\n",
    "        scores.append(newScore)\n",
    "        newLogLoss = log_loss(y_va, y_pred_sub)\n",
    "        newROCAUC = roc_auc_score(y_va, y_pred_sub)\n",
    "        print(\"loop %d, accuracy %0.6f, logloss %0.6f, roc_auc_score %0.6f\" % (i, newScore, newLogLoss, newROCAUC))\n",
    "        # preserve one pair of y_true and y_pred\n",
    "        if i == 1:\n",
    "            y_pred = y_pred_sub\n",
    "            y_true = y_va\n",
    "    scores_array = np.asarray(scores)\n",
    "    print(\"Accuracy: %0.6f (+/- %0.6f)\" % (scores_array.mean(), scores_array.std() * 2))\n",
    "    print()\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d877210d5c4b539aff4bd8e6fa0213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- evaluating toxic -----\n",
      "loop 1, accuracy 0.945825, logloss 1.871149, roc_auc_score 0.756012\n",
      "loop 2, accuracy 0.945134, logloss 1.895018, roc_auc_score 0.750223\n",
      "loop 3, accuracy 0.945572, logloss 1.879866, roc_auc_score 0.749606\n",
      "loop 4, accuracy 0.946763, logloss 1.838741, roc_auc_score 0.755740\n",
      "loop 5, accuracy 0.946795, logloss 1.837658, roc_auc_score 0.754921\n",
      "Accuracy: 0.946018 (+/- 0.001319)\n",
      "\n",
      "----- evaluating severe_toxic -----\n",
      "loop 1, accuracy 0.989660, logloss 0.357131, roc_auc_score 0.599018\n",
      "loop 2, accuracy 0.991164, logloss 0.305195, roc_auc_score 0.623302\n",
      "loop 3, accuracy 0.990130, logloss 0.340909, roc_auc_score 0.608910\n",
      "loop 4, accuracy 0.990192, logloss 0.338744, roc_auc_score 0.610146\n",
      "loop 5, accuracy 0.990098, logloss 0.341991, roc_auc_score 0.606578\n",
      "Accuracy: 0.990249 (+/- 0.000989)\n",
      "\n",
      "----- evaluating obscene -----\n",
      "loop 1, accuracy 0.974526, logloss 0.879841, roc_auc_score 0.792743\n",
      "loop 2, accuracy 0.974525, logloss 0.879868, roc_auc_score 0.786059\n",
      "loop 3, accuracy 0.974525, logloss 0.879868, roc_auc_score 0.790407\n",
      "loop 4, accuracy 0.975497, logloss 0.846318, roc_auc_score 0.797611\n",
      "loop 5, accuracy 0.975121, logloss 0.859306, roc_auc_score 0.794118\n",
      "Accuracy: 0.974839 (+/- 0.000803)\n",
      "\n",
      "----- evaluating threat -----\n",
      "loop 1, accuracy 0.996741, logloss 0.112550, roc_auc_score 0.514376\n",
      "loop 2, accuracy 0.996365, logloss 0.125541, roc_auc_score 0.517313\n",
      "loop 3, accuracy 0.997305, logloss 0.093073, roc_auc_score 0.528991\n",
      "loop 4, accuracy 0.997525, logloss 0.085497, roc_auc_score 0.524660\n",
      "loop 5, accuracy 0.997086, logloss 0.100649, roc_auc_score 0.521661\n",
      "Accuracy: 0.997004 (+/- 0.000822)\n",
      "\n",
      "----- evaluating insult -----\n",
      "loop 1, accuracy 0.965032, logloss 1.207753, roc_auc_score 0.714193\n",
      "loop 2, accuracy 0.965846, logloss 1.179653, roc_auc_score 0.712423\n",
      "loop 3, accuracy 0.965250, logloss 1.200215, roc_auc_score 0.713286\n",
      "loop 4, accuracy 0.967663, logloss 1.116882, roc_auc_score 0.726270\n",
      "loop 5, accuracy 0.966410, logloss 1.160172, roc_auc_score 0.716609\n",
      "Accuracy: 0.966040 (+/- 0.001886)\n",
      "\n",
      "----- evaluating identity_hate -----\n",
      "loop 1, accuracy 0.990819, logloss 0.317089, roc_auc_score 0.533214\n",
      "loop 2, accuracy 0.991508, logloss 0.293289, roc_auc_score 0.534199\n",
      "loop 3, accuracy 0.991728, logloss 0.285714, roc_auc_score 0.538896\n",
      "loop 4, accuracy 0.991070, logloss 0.308440, roc_auc_score 0.539614\n",
      "loop 5, accuracy 0.990600, logloss 0.324674, roc_auc_score 0.545538\n",
      "Accuracy: 0.991145 (+/- 0.000839)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "for i, label in tqdm(enumerate(labels)):\n",
    "    print(\"----- evaluating %s -----\" % label)\n",
    "    m = LogisticRegression()\n",
    "    y_true_sub, y_pred_sub = crossValidation(m, train_scaled, train[label])\n",
    "    y_true.append(y_true_sub)\n",
    "    y_pred.append(y_pred_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.concat([test[\"id\"], pd.DataFrame(predict_on_test)], axis=1, ignore_index = True)\n",
    "output_columns = ['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "out.columns = output_columns\n",
    "submission_file = open(\"../output/submission_logistic.csv\", \"w\")\n",
    "out.to_csv('../output/submission_logistic.csv', index = False)\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on Kaggle = 0.94415"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
